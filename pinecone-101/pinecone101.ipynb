{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e764c0b639c29"
      },
      "source": [
        "# Pinecone 101 Webinar\n",
        "\n",
        "\n",
        "\n",
        "The Pinecone Python client offers a user-friendly API that empowers developers to easily automate tasks and interact with the platform through the Python SDK. This makes it simple to create and manage vector indexes, perform efficient similarity searches, and handle large-scale machine learning and natural language processing workloads.\n",
        "\n",
        "This notebook will guide you through the initial steps of using the Pinecone Serverless platform.\n",
        "\n",
        "\n",
        "### Steps in This Notebook:\n",
        "\n",
        "1. Load Libraries\n",
        "2. Create Index\n",
        "3. UPSERT Sample Data\n",
        "4. Embed Query\n",
        "5. Execute Search\n",
        "6. View Results\n",
        "\n",
        "The dataset we will be using consists of randomly generated doctor’s notes sample data. The original JSON data has been embedded into vectors, which we will load into Pinecone.\n",
        "\n",
        "***Let’s go!***"
      ],
      "id": "2a4e764c0b639c29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "556eff6203b1aabe"
      },
      "source": [
        "## Install Libraries"
      ],
      "id": "556eff6203b1aabe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cdf512f7f2e30a9"
      },
      "outputs": [],
      "source": [
        "!pip install -qU pinecone-client==3.2.1 pinecone-notebooks tqdm\n",
        "\n"
      ],
      "id": "5cdf512f7f2e30a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd97362e7f072e7c"
      },
      "outputs": [],
      "source": [
        "from pinecone_notebooks.colab import Authenticate\n",
        "Authenticate()\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "id": "cd97362e7f072e7c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95e0fe4e1221078f"
      },
      "source": [
        "## Initialize Pinecone Connection"
      ],
      "id": "95e0fe4e1221078f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5adf940500c5209"
      },
      "outputs": [],
      "source": [
        "# Initialize connection to Pinecone (get API key at app.pinecone.io)\n",
        "api_key = os.getenv('PINECONE_API_KEY')\n",
        "\n",
        "# Configure Pinecone client\n",
        "pc = Pinecone(api_key=api_key, source_tag='pinecone-notebooks:pinecone-101')\n",
        "\n",
        "# Get cloud and region settings\n",
        "cloud = os.getenv('PINECONE_CLOUD', 'aws')\n",
        "region = os.getenv('PINECONE_REGION', 'us-east-1')\n",
        "\n",
        "# Define serverless specifications\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)\n",
        "\n",
        "# Define index name\n",
        "index_name = 'pinecone101'"
      ],
      "id": "e5adf940500c5209"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ef91d4dfc6f82f"
      },
      "source": [
        "## Create Index"
      ],
      "id": "e0ef91d4dfc6f82f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d39520699392163e"
      },
      "outputs": [],
      "source": [
        "# Check existing indexes\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "if index_name not in existing_indexes:\n",
        "    # Create index if it does not exist\n",
        "    pc.create_index(index_name, dimension=384, metric='cosine', spec=spec)\n",
        "    # Wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "    print(f\"Index {index_name} has been successfully created.\")\n",
        "else:\n",
        "    print(f\"Index {index_name} already exists.\")"
      ],
      "id": "d39520699392163e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd43e8e03c1d45b1"
      },
      "source": [
        "## Get Data\n",
        "The data is based on simulated doctor's notes for numerous patients."
      ],
      "id": "fd43e8e03c1d45b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdda781680e2d124"
      },
      "source": [
        "### Upload and Read Data"
      ],
      "id": "bdda781680e2d124"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a1b3bc1cfba4f99"
      },
      "outputs": [],
      "source": [
        "# Step 1: Upload the file from your local machine to Google Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Assuming the file is uploaded, read it into a DataFrame\n",
        "file_name = next(iter(uploaded.keys()))\n",
        "df = pd.read_json(file_name, orient='records', lines=True)\n",
        "\n",
        "# Show head of the DataFrame\n",
        "df.head()"
      ],
      "id": "4a1b3bc1cfba4f99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb651746fdab451c"
      },
      "source": [
        "### Connect to Index and Upload Data"
      ],
      "id": "eb651746fdab451c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "385bb027f485a52e"
      },
      "outputs": [],
      "source": [
        "# Connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "\n",
        "# View index stats\n",
        "index.describe_index_stats()\n",
        "\n",
        "# Upsert data into index from DataFrame\n",
        "index.upsert_from_dataframe(df)"
      ],
      "id": "385bb027f485a52e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "976d5cce9bc8efe6"
      },
      "source": [
        "## Embedding and Querying"
      ],
      "id": "976d5cce9bc8efe6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c543a5a38b1e99e7"
      },
      "source": [
        "### Define Embedding Function"
      ],
      "id": "c543a5a38b1e99e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506e4bb0798ceb48"
      },
      "outputs": [],
      "source": [
        "def get_embedding(input_question):\n",
        "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    encoded_input = tokenizer(input_question, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    embedding = model_output.last_hidden_state[0].mean(dim=0)\n",
        "    return embedding"
      ],
      "id": "506e4bb0798ceb48"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee57ce2b49f5914e"
      },
      "source": [
        "### Build and Execute Query"
      ],
      "id": "ee57ce2b49f5914e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6487ae2ff6aeef5"
      },
      "outputs": [],
      "source": [
        "# Build a query to search\n",
        "question = \"what if my patient has knee pain\"\n",
        "query = get_embedding(question).tolist()\n",
        "\n",
        "# Get results\n",
        "results = index.query(vector=[query], top_k=3, include_metadata=True)\n",
        "\n",
        "# Sort results by score in descending order\n",
        "sorted_matches = sorted(results['matches'], key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "# Print results\n",
        "print(f'Original question: {question}')\n",
        "print('---\\nResults:\\n--------------')\n",
        "for match in sorted_matches:\n",
        "    print(f'ID: {match[\"id\"]}')\n",
        "    print(f'Score: {match[\"score\"]}')\n",
        "    print(f'Metadata: {match[\"metadata\"]}')\n",
        "    print('---')"
      ],
      "id": "b6487ae2ff6aeef5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}